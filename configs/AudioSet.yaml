MODEL:
  META_ARCHITECTURE: "EndToEndHeteroGNN"
  AUDIO_BACKBONE:
    NAME: "WAV2VEC2_BASE"
    PRETRAINED_ON: ""
    FINETUNE: False
  VIDEO_BACKBONE:
    NAME: "r3d_18"
    PRETRAINED_ON: ""
    FINETUNE: False
  IMAGE_BACKBONE:
    NAME: "Resnext"
    PRETRAINED_ON: "ImageNet"
  HIDDEN_CHANNELS: 512
  NUM_LAYERS: 4
TRAINING:
#  LOSS: "FocalLoss"
  LOSS: "CrossEntropyLoss"
  TRAIN_PLOT_PERIOD: 100
GRAPH:
  DYNAMIC: False
#  SPAN_OVER_TIME_AUDIO: 5
#  AUDIO_DILATION: 3
#  SPAN_OVER_TIME_VIDEO: 3
#  VIDEO_DILATION: 2
#  SPAN_OVER_TIME_BETWEEN: 6
  SPAN_OVER_TIME_AUDIO: 2
  AUDIO_DILATION: 2
  SPAN_OVER_TIME_VIDEO: 3
  VIDEO_DILATION: 3
  SPAN_OVER_TIME_BETWEEN: 2
  NORMALIZE: False
  SELF_LOOPS: False
  RESIDUAL: True
  FUSION_LAYERS: [-1]
  NUM_VIDEO_NODES: 40
  NUM_AUDIO_NODES: 40
DATASETS:
  TRAIN_RATIO: 0.7
  EVAL_RATIO: 0.1
  TEST_RATIO: 0.2
  TRAIN_PATH: "/home/amir_shirian/Desktop/Codes/Cross_modality_graph/data/AudioSet/train"
  TEST_PATH: "/home/amir_shirian/Desktop/Codes/Cross_modality_graph/data/AudioSet/eval"
TEST:
  MAX_PATIENCE: 10
  EVAL_PERIOD: 2500
DATALOADER:
  BATCH_SIZE: 4
  STRATIFIED_SPLIT: True
  NUM_WORKERS: 6
SOLVER:
  BASE_LR: 0.0005
#  STEPS: (1500, 3200)
  STEPS: ()
  MAX_ITER: 100000
  WARMUP_ITERS: 1000
# number of epochs to be accumulated before updating the parameters
  ITERS_TO_ACCUMULATE: 1
# option to enable 16-bit training
  AMP:
    ENABLED: False
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
VERSION: 0
SEED: 1
WANDB:
  PROJECT_NAME: "CrossModalGraph"
  ENABLED: True
  CONFIG_PATH: "configs/wandb_config.yaml"
  PERIOD: 100